# autonomous_agency/app/agents/report_generator.py
import asyncio
import subprocess
import os
import json
import mimetypes
import re # Import regex
from datetime import datetime
from email.message import EmailMessage
from email.utils import formatdate, make_msgid
from typing import List, Optional, Dict, Any

import aiosmtplib
from sqlalchemy.ext.asyncio import AsyncSession
import httpx # Needed for LLM call for cleaning

# Assuming agent_utils defines get_httpx_client and call_llm_api
from Acumenis.app.agents.agent_utils import get_httpx_client, call_llm_api # Adjusted path
from Acumenis.app.core.config import settings # Adjusted path
from Acumenis.app.db import crud, models # Adjusted path
from Acumenis.app.core.security import decrypt_data # Adjusted path

# Define where reports will be stored (relative to the app root inside the container)
REPORTS_OUTPUT_DIR = "/app/generated_reports"
os.makedirs(REPORTS_OUTPUT_DIR, exist_ok=True)

# --- Report Cleaning Function ---
async def clean_report_content(client: httpx.AsyncClient, raw_content: str, filename: str) -> str:
    """Uses LLM to clean the raw report content."""
    cleaning_prompt = f"""
    Review the following raw research report content generated by an automated tool (filename: {filename}).
    Your task is to clean it up for professional delivery.

    Actions:
    1. Remove any headers, footers, or metadata clearly added by the generation tool (e.g., "Generated by...", tool version info, timestamps within the content body).
    2. Correct obvious formatting errors (e.g., inconsistent spacing, broken markdown).
    3. Ensure consistent markdown usage (e.g., use '**' for bold, '*' for italics, '#' for headers).
    4. Remove any placeholder text like "[insert analysis here]" or similar.
    5. Check for and remove repetitive sentences or paragraphs if they don't add value.
    6. DO NOT add new content or analysis. Focus solely on cleaning and formatting.
    7. DO NOT remove citations if they are present (e.g., [1], [^2^]).
    8. Output ONLY the cleaned report content as a single block of markdown text. No preamble, no explanation, just the cleaned report.

    Raw Content:
    ---
    {raw_content}
    ---

    Cleaned Content:
    """
    print(f"[ReportCleaner] Cleaning report content for {filename} using LLM...")
    llm_response = await call_llm_api(client, cleaning_prompt, model="google/gemini-1.5-flash-latest") # Use a fast model for cleaning

    if llm_response and isinstance(llm_response.get("raw_inference"), str):
        cleaned = llm_response["raw_inference"].strip()
        # Basic check: ensure it's not empty and seems like report content
        if len(cleaned) > 50:
            print(f"[ReportCleaner] Cleaning successful for {filename}.")
            return cleaned
        else:
            print(f"[ReportCleaner] LLM cleaning resulted in very short content for {filename}. Using raw content.")
            return raw_content
    else:
        print(f"[ReportCleaner] LLM cleaning failed for {filename}. Using raw content.")
        return raw_content


# --- Email Delivery Function ---
async def _send_delivery_email(request_id: int, report_path: str, cleaned_content: Optional[str] = None):
    """
    Handles sending the delivery email with attachment or cleaned content.
    Gets its own DB session. Updates ReportRequest status directly.
    """
    print(f"[ReportDelivery] Task started for request ID: {request_id}")
    session: AsyncSession = None
    request: Optional[models.ReportRequest] = None
    delivery_account: Optional[models.EmailAccount] = None
    success = False

    try:
        session = await crud.get_worker_session() # Get a new session for this task
        request = await session.get(models.ReportRequest, request_id)
        if not request:
            print(f"[ReportDelivery] Error: ReportRequest ID {request_id} not found in DB.")
            return # Cannot proceed

        print(f"[ReportDelivery] Attempting delivery for request ID: {request.request_id} to {request.client_email}")
        delivery_account = await crud.get_active_email_account_for_sending(session)

        if not delivery_account:
            print(f"[ReportDelivery] No active sending account found for request {request.request_id}.")
            request.status = "DELIVERY_FAILED"
            request.error_message = "No active email account available for delivery."
            await session.commit()
            return # Stop processing this email

        decrypted_password = decrypt_data(delivery_account.smtp_password_encrypted)
        if not decrypted_password:
            print(f"[ReportDelivery] CRITICAL: Failed to decrypt password for account {delivery_account.email_address}. Cannot send report {request.request_id}.")
            request.status = "DELIVERY_FAILED"
            request.error_message = "Internal Error: Failed to decrypt sender email password."
            # Optionally deactivate account here? Risky if decryption is transient issue.
            await session.commit()
            return # Stop processing this email

        report_filename_base = f"Acumenis_Report_{request.request_id}_{request.report_type}"
        report_filename_md = f"{report_filename_base}.md"

        subject = f"Your Acumenis AI Research Report is Ready! (Request ID: {request.request_id})"
        body_intro = f"Hi {request.client_name or 'Client'},\n\nYour requested AI research report (Request ID: {request.request_id}) has been generated successfully.\n\n"
        body_main = ""
        body_outro = f"\n\nIf you have any questions or need further analysis, please don't hesitate to reach out.\n\nBest regards,\nThe Acumenis Team\n{settings.AGENCY_BASE_URL}"

        msg = EmailMessage()
        msg['Subject'] = subject
        msg['From'] = delivery_account.email_address
        msg['To'] = request.client_email
        msg['Date'] = formatdate(localtime=True)
        msg['Message-ID'] = make_msgid(domain=delivery_account.email_address.split('@')[-1])

        # Attachment Logic (Prioritize cleaned content)
        if cleaned_content:
            body_main = "Please find the cleaned report attached as a Markdown file."
            msg.add_attachment(cleaned_content.encode('utf-8'), maintype='text', subtype='markdown', filename=report_filename_md)
            print(f"[ReportDelivery] Attaching cleaned markdown report: {report_filename_md}")
        elif os.path.exists(report_path):
            body_main = "Please find the generated report attached."
            ctype, encoding = mimetypes.guess_type(report_path)
            if ctype is None or encoding is not None: ctype = 'application/octet-stream'
            maintype, subtype = ctype.split('/', 1)
            try:
                with open(report_path, 'rb') as fp:
                    msg.add_attachment(fp.read(), maintype=maintype, subtype=subtype, filename=os.path.basename(report_path))
                print(f"[ReportDelivery] Attached raw report file: {os.path.basename(report_path)}")
            except Exception as attach_e:
                print(f"[ReportDelivery] Failed to attach raw report file {report_path}: {attach_e}")
                body_main = f"[Attachment Error: Could not attach report file '{os.path.basename(report_path)}'. Please contact support.]"
        else:
            print(f"[ReportDelivery] Report file not found at path: {report_path}. Sending email without attachment.")
            body_main = f"[Delivery Error: Report file '{os.path.basename(report_path)}' not found. Please contact support.]"

        msg.set_content(body_intro + body_main + body_outro)

        # Send using aiosmtplib
        try:
            async with aiosmtplib.SMTP(hostname=delivery_account.smtp_host, port=delivery_account.smtp_port, use_tls=True, timeout=45) as smtp:
                await smtp.login(delivery_account.smtp_user, decrypted_password)
                await smtp.send_message(msg)
            print(f"[ReportDelivery] Delivery email sent successfully for request ID: {request.request_id}")
            await crud.increment_email_sent_count(session, delivery_account.account_id)
            request.status = "COMPLETED" # Final success status
            request.error_message = None # Clear any previous error
            success = True

        except aiosmtplib.SMTPAuthenticationError as auth_err:
            print(f"[ReportDelivery] SMTP Auth Error for {delivery_account.email_address}: {auth_err}. Deactivating account.")
            await crud.set_email_account_inactive(session, delivery_account.account_id, reason=f"Auth Error: {auth_err}")
            request.status = "DELIVERY_FAILED"
            request.error_message = f"Sender Auth Error: Account {delivery_account.email_address} deactivated."

        except aiosmtplib.SMTPRecipientsRefused as recip_err:
            print(f"[ReportDelivery] SMTP Recipient Refused for {request.client_email}: {recip_err}. Marking as DELIVERY_FAILED.")
            request.status = "DELIVERY_FAILED"
            request.error_message = f"Recipient Refused: {recip_err}"

        except Exception as smtp_e:
            print(f"[ReportDelivery] SMTP Error sending report for request ID {request.request_id} via {delivery_account.email_address}: {smtp_e}")
            request.status = "DELIVERY_FAILED"
            request.error_message = f"SMTP Error: {str(smtp_e)[:200]}" # Store truncated error

        # Commit final status update within this task's session
        await session.commit()

    except Exception as e:
        print(f"[ReportDelivery] Unexpected error in delivery task for request {request_id}: {e}")
        import traceback
        traceback.print_exc()
        # Attempt to update status if possible
        if session and request and request.status != "COMPLETED":
            try:
                request.status = "DELIVERY_FAILED"
                request.error_message = f"Internal Delivery Error: {str(e)[:200]}"
                await session.commit()
            except Exception as final_e:
                print(f"[ReportDelivery] Failed to update status after unexpected error: {final_e}")
                await session.rollback() # Rollback if final update fails
    finally:
        if session:
            await session.close()
        print(f"[ReportDelivery] Task finished for request ID: {request_id}. Success: {success}")


# --- Main Report Processing Function ---
async def process_single_report_request(db: AsyncSession, request: models.ReportRequest):
    """
    Processes a single report request using the open-deep-research tool,
    updates status, cleans the report, and attempts email delivery on completion.
    """
    print(f"[ReportGenerator] Processing request ID: {request.request_id} for '{request.request_details[:50]}...'")
    client: Optional[httpx.AsyncClient] = None # Define client for LLM call for cleaning
    process_success = False
    final_status = "FAILED"
    error_message = "Processing did not complete."
    output_path = None
    cleaned_report_content = None

    # Define timeout for the external process
    # Use a dedicated setting if available, otherwise calculate based on interval
    report_timeout = settings.REPORT_GENERATOR_TIMEOUT_SECONDS or (settings.REPORT_GENERATOR_INTERVAL_SECONDS * 10)

    try:
        # 1. Update status to PROCESSING (Commit handled by worker loop)
        request.status = "PROCESSING"
        await db.flush() # Flush to make change visible within transaction if needed elsewhere
        print(f"[ReportGenerator] Set status to PROCESSING for request ID: {request.request_id}")

        # 2. Prepare command for open-deep-research
        query = request.request_details
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_query_part = "".join(c if c.isalnum() else "_" for c in query[:30])
        output_filename = f"report_{request.request_id}_{safe_query_part}_{timestamp}.md"
        output_path = os.path.join(REPORTS_OUTPUT_DIR, output_filename)

        node_script_path = os.path.join(settings.OPEN_DEEP_RESEARCH_REPO_PATH, settings.OPEN_DEEP_RESEARCH_ENTRY_POINT)

        if not os.path.exists(settings.NODE_EXECUTABLE_PATH):
             raise FileNotFoundError(f"Node executable not found at: {settings.NODE_EXECUTABLE_PATH}")
        if not os.path.exists(node_script_path):
             raise FileNotFoundError(f"open-deep-research entry point not found at: {node_script_path}")

        cmd = [
            settings.NODE_EXECUTABLE_PATH,
            node_script_path,
            "--query", query,
            "--output", output_path,
        ]
        # Add conditional arguments
        if request.report_type == 'premium_999':
            cmd.extend(["--depth", "5"])
            cmd.extend(["--model", settings.PREMIUM_REPORT_MODEL or "google/gemini-1.5-pro-latest"])
        else: # Standard or unknown
            cmd.extend(["--model", settings.STANDARD_REPORT_MODEL or "google/gemini-1.5-flash-latest"])

        print(f"[ReportGenerator] Executing command: {' '.join(cmd)} in {settings.OPEN_DEEP_RESEARCH_REPO_PATH}")

        # 3. Execute the open-deep-research tool using asyncio.create_subprocess_exec
        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
            cwd=settings.OPEN_DEEP_RESEARCH_REPO_PATH
        )

        # Wait for the process to complete with a timeout
        try:
            stdout, stderr = await asyncio.wait_for(process.communicate(), timeout=report_timeout)
        except asyncio.TimeoutError:
            print(f"[ReportGenerator] Subprocess timed out after {report_timeout} seconds. Terminating.")
            try:
                process.terminate()
                await asyncio.wait_for(process.wait(), timeout=5.0) # Wait briefly for termination
            except asyncio.TimeoutError:
                print("[ReportGenerator] Process did not terminate gracefully after timeout, killing.")
                process.kill()
            except ProcessLookupError:
                pass # Process already finished
            except Exception as term_e:
                print(f"[ReportGenerator] Error during process termination: {term_e}")
            raise TimeoutError(f"Report generation subprocess timed out after {report_timeout} seconds.") # Re-raise specific error

        stdout_decoded = stdout.decode(errors='ignore').strip() if stdout else ""
        stderr_decoded = stderr.decode(errors='ignore').strip() if stderr else ""

        print(f"[ReportGenerator] Subprocess exited with code: {process.returncode}")
        if stdout_decoded: print(f"[ReportGenerator] Subprocess STDOUT:\n{stdout_decoded[:1000]}...")
        if stderr_decoded: print(f"[ReportGenerator] Subprocess STDERR:\n{stderr_decoded[:1000]}...")

        # 4. Check result and clean
        if process.returncode == 0 and os.path.exists(output_path) and os.path.getsize(output_path) > 50:
            print(f"[ReportGenerator] Raw report generated successfully: {output_path}")
            raw_content = ""
            try:
                with open(output_path, 'r', encoding='utf-8') as f:
                    raw_content = f.read()
            except Exception as read_e:
                raise IOError(f"Failed to read generated report file {output_path}: {read_e}")

            # Clean the content using LLM
            client = await get_httpx_client()
            try:
                cleaned_report_content = await clean_report_content(client, raw_content, output_filename)
            finally:
                await client.aclose() # Ensure client is closed

            # Overwrite the original file with cleaned content
            try:
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(cleaned_report_content)
                print(f"[ReportGenerator] Report cleaned and saved: {output_path}")
            except Exception as write_e:
                 raise IOError(f"Failed to write cleaned report file {output_path}: {write_e}")

            final_status = "GENERATED" # Intermediate status before delivery attempt
            process_success = True
            error_message = None
        elif process.returncode == 0:
            error_message = "Generation process succeeded but output file is missing, empty or too small."
            print(f"[ReportGenerator] Error: {error_message}")
            if output_path and os.path.exists(output_path):
                try: os.remove(output_path)
                except OSError: pass
            output_path = None # Don't save path if file is invalid
            final_status = "FAILED"
        else:
            error_message = f"Generation failed. Exit code: {process.returncode}. Stderr: {stderr_decoded[:500]}"
            print(f"[ReportGenerator] Error: {error_message}")
            if output_path and os.path.exists(output_path):
                try: os.remove(output_path)
                except OSError: pass
            output_path = None
            final_status = "FAILED"

    except FileNotFoundError as e:
        error_message = f"Execution failed: Command or script not found. Check paths in config. Error: {e}"
        print(f"[ReportGenerator] Error: {error_message}")
        final_status = "FAILED"
        output_path = None
    except TimeoutError as e: # Catch the specific re-raised error
        error_message = str(e)
        print(f"[ReportGenerator] Error: {error_message}")
        final_status = "FAILED"
        output_path = None
    except Exception as e:
        error_message = f"Unexpected error during report generation: {str(e)[:500]}" # Truncate long errors
        print(f"[ReportGenerator] Error: {error_message}")
        import traceback
        traceback.print_exc()
        final_status = "FAILED"
        if output_path and os.path.exists(output_path):
            try: os.remove(output_path)
            except OSError: pass
        output_path = None
    # No finally block needed for client closing, handled within the success path

    # 5. Update DB object with generation status (Commit handled by worker loop)
    request.status = final_status
    request.report_output_path = output_path
    request.error_message = error_message
    await db.flush() # Flush changes within the transaction
    print(f"[ReportGenerator] Finished generation phase for request ID: {request.request_id} with status: {final_status}")

    # --- 6. Attempt Delivery if Generation Succeeded ---
    if process_success and final_status == "GENERATED" and output_path:
        # Pass necessary info directly, _send_delivery_email gets its own session
        # Run delivery in background task to avoid blocking worker loop
        print(f"[ReportGenerator] Scheduling delivery task for request ID: {request.request_id}")
        asyncio.create_task(_send_delivery_email(request.request_id, output_path, cleaned_report_content))

    elif final_status == "FAILED":
         print(f"[ReportGenerator] Report generation failed for request {request.request_id}. No delivery attempted.")